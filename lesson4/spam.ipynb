{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d577b-1ebb-4a38-8b7b-2397ae1f57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./spam.csv\", encoding=\"ISO-8859-1\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694d516-6613-4d71-b7ec-41057682ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dce683-715c-4704-9f82-3ddfaf852903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of these columns look suspicious.\n",
    "# Let's explore what's in there\n",
    "\n",
    "cols = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"]\n",
    "\n",
    "for col in cols:\n",
    "    uniq_vals = data[col].unique()\n",
    "    print(f\"{len(uniq_vals)} unique value(s) for {col}:\")\n",
    "    print(uniq_vals)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe84b02-01d5-475d-bd58-b1dbc23e0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like the values in these unnamed cols are a result of\n",
    "# badly structured CSV. Let's merge them so we end up with 2 columns:\n",
    "# v1: spam/ham\n",
    "# v2: email content\n",
    "\n",
    "# first, clean NaN values:\n",
    "data.fillna(\"\")\n",
    "\n",
    "# print(cols[0])\n",
    "\n",
    "# then, merge all 3 lame cols into one:\n",
    "resulting_col = (data[cols[0]] + data[cols[1]] + data[cols[2]]).fillna(\"\")\n",
    "\n",
    "# # then, update v2 col\n",
    "data[\"v2\"] += resulting_col\n",
    "\n",
    "# finally, drop the unnecessary cols:\n",
    "data = data.drop(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4116b-c933-4312-9765-585ebaa0a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025aabb-9d4a-4541-93f9-99455f7a285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a numerical label\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = data[\"v1\"].unique()\n",
    "enc = LabelEncoder()\n",
    "enc.fit(labels)\n",
    "label_map = dict(zip(enc.classes_, enc.transform(enc.classes_)))\n",
    "print(label_map)\n",
    "data[\"labels\"] = enc.transform(data[\"v1\"])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cb159-a791-43f9-af47-af4e9d3e73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll split the dataset into a train (80%) and test (20%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"v2\"], data[\"labels\"], test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51c99b-717c-49b9-9470-b607d524a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the email texts into tokens\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fb83a-affa-4e18-bc90-2946861aeef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf4d8b-e840-450a-845c-879d5e305af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the trained model over the test data and evaluate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada5fe9-6b03-45cf-a63e-5b61f5f8230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the same, this time using a different model:\n",
    "# k-Means clustering into 2 clusters\n",
    "# We'll use a different approach to evaluate the model\n",
    "\n",
    "X = vectorizer.fit_transform(data[\"v2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018655fe-2b47-4016-b1b0-6fff1d8e55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=69)\n",
    "data[\"result\"] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02517451-a808-40a1-b8d1-f9a1476f9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a151ff-62cb-4450-85ac-ceb7fdee1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(expected_label, actual_label):\n",
    "    return len(data[(data[\"v1\"] == expected_label) & (data[\"result\"] == label_map[actual_label])])\n",
    "\n",
    "true_positives = counter(\"spam\", \"spam\")\n",
    "true_negatives = counter(\"ham\", \"ham\")\n",
    "false_positives = counter(\"ham\", \"spam\")\n",
    "false_negatives = counter(\"spam\", \"ham\")\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"f1: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
